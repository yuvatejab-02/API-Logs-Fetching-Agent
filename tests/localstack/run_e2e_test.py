#!/usr/bin/env python3
"""
End-to-End Test Orchestrator for Incident Log Analyzer

This script runs all component tests and generates a comprehensive test report
showing the complete data flow through the system.
"""
import json
import sys
import subprocess
from pathlib import Path
from datetime import datetime, timezone
import time

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


class E2ETestOrchestrator:
    """Orchestrates end-to-end testing with detailed reporting."""
    
    def __init__(self):
        """Initialize the test orchestrator."""
        self.test_components_dir = Path(__file__).parent / "test_components"
        self.reports_dir = Path(__file__).parent.parent / "reports"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
        self.test_results = {
            "test_suite": "incident_log_analyzer_e2e",
            "started_at": datetime.now(timezone.utc).isoformat(),
            "completed_at": None,
            "duration_seconds": 0,
            "total_tests": 0,
            "passed": 0,
            "failed": 0,
            "component_tests": [],
            "data_flow": {
                "incident_payload": None,
                "llm_query": None,
                "signoz_logs": None,
                "s3_storage": None
            }
        }
    
    def print_header(self):
        """Print test suite header."""
        print("\n" + "="*80)
        print("  üß™ END-TO-END TEST SUITE - INCIDENT LOG ANALYZER")
        print("="*80)
        print(f"\n  Started: {self.test_results['started_at']}")
        print("  Test Components: LLM Query ‚Üí SigNoz Fetch ‚Üí S3 Storage")
        print("\n" + "="*80 + "\n")
    
    def run_component_test(self, test_name, test_file):
        """Run a single component test."""
        print(f"\n{'‚îÄ'*80}")
        print(f"  Running: {test_name}")
        print(f"{'‚îÄ'*80}\n")
        
        test_path = self.test_components_dir / test_file
        start_time = time.time()
        
        try:
            # Run the test
            result = subprocess.run(
                [sys.executable, str(test_path)],
                capture_output=True,
                text=True,
                timeout=120
            )
            
            duration = time.time() - start_time
            passed = result.returncode == 0
            
            # Print output
            print(result.stdout)
            if result.stderr:
                print("STDERR:", result.stderr)
            
            # Record result
            test_result = {
                "test_name": test_name,
                "test_file": test_file,
                "status": "passed" if passed else "failed",
                "duration_seconds": round(duration, 2),
                "return_code": result.returncode
            }
            
            # Try to load the generated report
            self._load_test_report(test_result)
            
            self.test_results["component_tests"].append(test_result)
            self.test_results["total_tests"] += 1
            
            if passed:
                self.test_results["passed"] += 1
                print(f"‚úÖ {test_name} PASSED ({duration:.2f}s)\n")
            else:
                self.test_results["failed"] += 1
                print(f"‚ùå {test_name} FAILED ({duration:.2f}s)\n")
            
            return passed
            
        except subprocess.TimeoutExpired:
            print(f"‚ùå {test_name} TIMEOUT\n")
            self.test_results["failed"] += 1
            return False
        except Exception as e:
            print(f"‚ùå {test_name} ERROR: {e}\n")
            self.test_results["failed"] += 1
            return False
    
    def _load_test_report(self, test_result):
        """Load the JSON report generated by a test."""
        try:
            # Find the most recent report for this test
            test_prefix = test_result["test_file"].replace(".py", "").replace("test_", "")
            report_files = list(self.reports_dir.glob(f"{test_prefix}_*.json"))
            
            if report_files:
                # Get the most recent
                latest_report = max(report_files, key=lambda p: p.stat().st_mtime)
                
                with open(latest_report, 'r') as f:
                    report_data = json.load(f)
                
                test_result["report_data"] = report_data
                
                # Add to data flow
                if "01_llm" in test_prefix:
                    self.test_results["data_flow"]["llm_query"] = report_data.get("output")
                    self.test_results["data_flow"]["incident_payload"] = report_data.get("input", {}).get("incident_payload")
                elif "02_signoz" in test_prefix:
                    self.test_results["data_flow"]["signoz_logs"] = report_data.get("output")
                elif "03_s3" in test_prefix:
                    self.test_results["data_flow"]["s3_storage"] = report_data.get("output")
        
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Could not load report: {e}")
    
    def run_all_tests(self):
        """Run all component tests in sequence."""
        self.print_header()
        
        start_time = time.time()
        
        # Test sequence
        tests = [
            ("Component 01: LLM Query Generation", "01_test_llm_query.py"),
            ("Component 02: SigNoz Fetch & Transform", "02_test_signoz_fetch.py"),
            ("Component 03: S3 Storage", "03_test_s3_storage.py")
        ]
        
        all_passed = True
        for test_name, test_file in tests:
            passed = self.run_component_test(test_name, test_file)
            if not passed:
                all_passed = False
                # Continue with other tests even if one fails
        
        # Calculate totals
        self.test_results["duration_seconds"] = round(time.time() - start_time, 2)
        self.test_results["completed_at"] = datetime.now(timezone.utc).isoformat()
        
        return all_passed
    
    def generate_report(self):
        """Generate comprehensive test report."""
        print("\n" + "="*80)
        print("  üìä TEST SUMMARY")
        print("="*80 + "\n")
        
        print(f"Total Tests: {self.test_results['total_tests']}")
        print(f"Passed: {self.test_results['passed']} ‚úÖ")
        print(f"Failed: {self.test_results['failed']} ‚ùå")
        print(f"Duration: {self.test_results['duration_seconds']}s")
        
        # Component results
        print(f"\n{'‚îÄ'*80}")
        print("Component Results:")
        print(f"{'‚îÄ'*80}\n")
        
        for test in self.test_results["component_tests"]:
            status_icon = "‚úÖ" if test["status"] == "passed" else "‚ùå"
            print(f"{status_icon} {test['test_name']}: {test['status'].upper()} ({test['duration_seconds']}s)")
        
        # Data flow summary
        print(f"\n{'‚îÄ'*80}")
        print("üìà Data Flow Summary:")
        print(f"{'‚îÄ'*80}\n")
        
        # Incident payload
        incident = self.test_results["data_flow"].get("incident_payload")
        if incident:
            print(f"1Ô∏è‚É£  Incident Payload:")
            print(f"    ID: {incident.get('incident_id')}")
            print(f"    Service: {incident.get('service', {}).get('name')}")
            print(f"    Title: {incident.get('title')}\n")
        
        # LLM Query
        llm_query = self.test_results["data_flow"].get("llm_query")
        if llm_query:
            print(f"2Ô∏è‚É£  LLM Generated Query:")
            print(f"    Filter: {llm_query.get('filter_expression', 'N/A')[:70]}...")
            print(f"    Reasoning: {llm_query.get('reasoning', 'N/A')[:60]}...\n")
        
        # SigNoz logs
        signoz = self.test_results["data_flow"].get("signoz_logs")
        if signoz:
            print(f"3Ô∏è‚É£  SigNoz Fetch:")
            print(f"    Logs Fetched: {signoz.get('logs_fetched', 0)}")
            sample = signoz.get('sample_log')
            if sample:
                print(f"    Sample Log:")
                print(f"      - Service: {sample.get('service')}")
                print(f"      - Level: {sample.get('level')}")
                print(f"      - Status: {sample.get('status_code')}\n")
        
        # S3 storage
        s3 = self.test_results["data_flow"].get("s3_storage")
        if s3:
            print(f"4Ô∏è‚É£  S3 Storage:")
            print(f"    Bucket: {s3.get('s3_bucket')}")
            print(f"    Endpoint: {s3.get('s3_endpoint')}")
            print(f"    Files: {s3.get('files_in_incident', 0)}\n")
        
        print("="*80 + "\n")
        
        # Save comprehensive report
        report_file = self.reports_dir / f"e2e_test_report_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
        
        print(f"üìÑ Full report saved: {report_file}\n")
        
        return self.test_results["failed"] == 0


def main():
    """Main entry point."""
    orchestrator = E2ETestOrchestrator()
    
    try:
        # Run all tests
        all_passed = orchestrator.run_all_tests()
        
        # Generate report
        success = orchestrator.generate_report()
        
        if success:
            print("="*80)
            print("  ‚úÖ ALL TESTS PASSED")
            print("="*80 + "\n")
            return 0
        else:
            print("="*80)
            print("  ‚ùå SOME TESTS FAILED")
            print("="*80 + "\n")
            return 1
    
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Tests interrupted by user\n")
        return 130
    except Exception as e:
        print(f"\n\n‚ùå Test suite error: {e}\n")
        return 1


if __name__ == "__main__":
    sys.exit(main())
